{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 31041,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Batch normalized, ridge learning rate for outer layer, he initialised.\n",
        "\n",
        "initially a fully connected MLP is trained for 20 epochs then we introduce pruning based on the weights magnitude(weak ones deleted). The new links are made in the non adjacent layers. and weights are 'he' initialised\n",
        "Asynchnorous learning: layers involving outer layer ridge regression based learning function, others regular sgd. Accuracy increased till 65.18%"
      ],
      "metadata": {
        "id": "nfz9tucJ4YVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "3vc6Xadc__mE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import os"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T14:07:14.647348Z",
          "iopub.execute_input": "2025-07-04T14:07:14.648064Z",
          "iopub.status.idle": "2025-07-04T14:07:14.65215Z",
          "shell.execute_reply.started": "2025-07-04T14:07:14.648038Z",
          "shell.execute_reply": "2025-07-04T14:07:14.651409Z"
        },
        "id": "WgE9RpCD__mS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Enable GPU memory growth\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    for gpu in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    print(f\"✅ Running on GPU: {physical_devices[0].name}\")\n",
        "else:\n",
        "    print(\"⚠️ No GPU found. Running on CPU.\")\n",
        "\n",
        "class MLP_CIFAR10:\n",
        "    def __init__(self):\n",
        "        self.batch_size = 100\n",
        "        self.maxepoches = 100\n",
        "        self.initial_epochs = 20\n",
        "        self.learning_rate = 0.01\n",
        "        self.num_classes = 10\n",
        "        self.momentum = 0.9\n",
        "        self.prune_percent = 0.1  # 10% pruning\n",
        "\n",
        "        self.create_model()\n",
        "        self.train()\n",
        "\n",
        "    def create_model(self):\n",
        "        self.model = Sequential()\n",
        "        self.model.add(Flatten(input_shape=(32, 32, 3)))\n",
        "        self.model.add(Dense(4000, kernel_initializer='he_uniform'))\n",
        "        self.model.add(BatchNormalization())                     # Layer 1\n",
        "        self.model.add(Activation('relu'))\n",
        "        self.model.add(Dropout(0.3))\n",
        "        self.model.add(Dense(1000, kernel_initializer='he_uniform'))\n",
        "        self.model.add(BatchNormalization())                 # Layer 2\n",
        "        self.model.add(Activation('relu'))\n",
        "        self.model.add(Dropout(0.3))\n",
        "        self.model.add(Dense(4000, kernel_initializer='he_uniform'))\n",
        "        self.model.add(BatchNormalization())               # Layer 3\n",
        "        self.model.add(Activation('relu'))\n",
        "        self.model.add(Dropout(0.3))\n",
        "        self.model.add(Dense(self.num_classes, activation='softmax', kernel_initializer='he_uniform', name=\"output_layer\"))\n",
        "\n",
        "    def train(self):\n",
        "        x_train, y_train, x_test, y_test = self.read_data()\n",
        "\n",
        "        datagen = ImageDataGenerator(\n",
        "            rotation_range=10,\n",
        "            width_shift_range=0.1,\n",
        "            height_shift_range=0.1,\n",
        "            horizontal_flip=True\n",
        "        )\n",
        "        datagen.fit(x_train)\n",
        "\n",
        "        # Freeze output layer\n",
        "        self.model.get_layer(\"output_layer\").trainable = False\n",
        "\n",
        "        # Print model summary and active parameters\n",
        "        self.model.summary()\n",
        "        print(f\"\\n[INFO] Initial active parameters: {self.count_total_nonzero_weights()}\")\n",
        "\n",
        "        sgd = SGD(learning_rate=self.learning_rate, momentum=self.momentum)\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "        print(\"\\n[PHASE 1] Initial Training\")\n",
        "        self.model.fit(\n",
        "            datagen.flow(x_train, y_train, batch_size=self.batch_size),\n",
        "            epochs=self.initial_epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            steps_per_epoch=len(x_train) // self.batch_size,\n",
        "            verbose=2\n",
        "        )\n",
        "\n",
        "        print(\"\\n[PHASE 2] Pruning and Rewiring\")\n",
        "        total_before = self.count_total_nonzero_weights()\n",
        "        self.prune_weights(self.prune_percent)\n",
        "        total_after_prune = self.count_total_nonzero_weights()\n",
        "        rewiring_needed = total_before - total_after_prune\n",
        "        self.rewire_model_balanced(rewiring_needed)\n",
        "        total_after_rewire = self.count_total_nonzero_weights()\n",
        "\n",
        "        print(f\"[INFO] Non-zero weights: before={total_before}, after prune={total_after_prune}, after rewire={total_after_rewire}\")\n",
        "\n",
        "        print(\"\\n[PHASE 3] Final Training\")\n",
        "        history = self.model.fit(\n",
        "            datagen.flow(x_train, y_train, batch_size=self.batch_size),\n",
        "            epochs=self.maxepoches,\n",
        "            initial_epoch=self.initial_epochs,\n",
        "            validation_data=(x_test, y_test),\n",
        "            steps_per_epoch=len(x_train) // self.batch_size,\n",
        "            verbose=2\n",
        "        )\n",
        "\n",
        "        # Train output layer using Ridge Regression\n",
        "        self.train_output_layer_with_ridge(x_train, y_train)\n",
        "\n",
        "        self.accuracies_per_epoch = history.history['val_accuracy']\n",
        "\n",
        "    def train_output_layer_with_ridge(self, x_train, y_train, alpha=1.0):\n",
        "        feature_model = Model(inputs=self.model.input, outputs=self.model.get_layer(index=-2).output)\n",
        "        features = feature_model.predict(x_train, batch_size=self.batch_size)\n",
        "\n",
        "        ridge = Ridge(alpha=alpha, fit_intercept=True)\n",
        "        ridge.fit(features, y_train)\n",
        "\n",
        "        weights = ridge.coef_.T\n",
        "        biases = ridge.intercept_\n",
        "        self.model.get_layer(\"output_layer\").set_weights([weights, biases])\n",
        "        print(\"[INFO] ✅ Output layer learned via Ridge Regression.\")\n",
        "\n",
        "    def read_data(self):\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        y_train = to_categorical(y_train, self.num_classes)\n",
        "        y_test = to_categorical(y_test, self.num_classes)\n",
        "        x_train = x_train.astype('float32') / 255.0\n",
        "        x_test = x_test.astype('float32') / 255.0\n",
        "        return x_train, y_train, x_test, y_test\n",
        "\n",
        "    def count_total_nonzero_weights(self):\n",
        "        total = 0\n",
        "        for layer in self.model.layers:\n",
        "            if isinstance(layer, Dense):\n",
        "                W, _ = layer.get_weights()\n",
        "                total += np.count_nonzero(W)\n",
        "        return total\n",
        "\n",
        "    def prune_weights(self, prune_percent=0.2):\n",
        "        for layer in self.model.layers:\n",
        "            if isinstance(layer, Dense):\n",
        "                weights, biases = layer.get_weights()\n",
        "                flat = np.abs(weights.flatten())\n",
        "                threshold = np.percentile(flat, prune_percent * 100)\n",
        "                weights[np.abs(weights) < threshold] = 0.0\n",
        "                layer.set_weights([weights, biases])\n",
        "\n",
        "    def he_uniform_init(self, fan_in):\n",
        "        limit = np.sqrt(6.0 / fan_in)\n",
        "        return np.random.uniform(-limit, limit)\n",
        "\n",
        "    def rewire_model_balanced(self, rewiring_needed, seed=42):\n",
        "        print(f\"\\n[INFO] Rewiring {rewiring_needed} connections with HE initialization...\")\n",
        "\n",
        "        np.random.seed(seed)\n",
        "        dense_layers = [layer for layer in self.model.layers if isinstance(layer, Dense)]\n",
        "        layer_weights = [layer.get_weights() for layer in dense_layers]\n",
        "\n",
        "        valid_layer_pairs = [(i, j) for i in range(len(dense_layers))\n",
        "                            for j in range(len(dense_layers)) if abs(i - j) > 1]\n",
        "\n",
        "        per_pair = rewiring_needed // len(valid_layer_pairs)\n",
        "        connections_added = 0\n",
        "\n",
        "        for (src_idx, dst_idx) in valid_layer_pairs:\n",
        "            W_src, _ = layer_weights[src_idx]\n",
        "            W_dst, b_dst = layer_weights[dst_idx]\n",
        "\n",
        "            src_neurons = np.where(np.any(W_src != 0, axis=0))[0]\n",
        "            dst_neurons = np.where(np.any(W_dst == 0, axis=1))[0]\n",
        "\n",
        "            if len(src_neurons) == 0 or len(dst_neurons) == 0:\n",
        "                continue\n",
        "\n",
        "            k = min(per_pair, len(src_neurons) * len(dst_neurons))\n",
        "            new_dst_idxs = np.random.choice(dst_neurons, size=k, replace=True)\n",
        "            new_src_idxs = np.random.choice(src_neurons, size=k, replace=True)\n",
        "\n",
        "            for d, s in zip(new_dst_idxs, new_src_idxs):\n",
        "                if W_dst[d, s % W_dst.shape[1]] == 0:\n",
        "                    fan_in = W_src.shape[0]\n",
        "                    W_dst[d, s % W_dst.shape[1]] = self.he_uniform_init(fan_in)\n",
        "                    connections_added += 1\n",
        "\n",
        "            layer_weights[dst_idx][0] = W_dst\n",
        "\n",
        "        for i, layer in enumerate(dense_layers):\n",
        "            layer.set_weights(layer_weights[i])\n",
        "\n",
        "        print(f\"[INFO] ✅ Rewiring complete. Connections added: {connections_added}\")\n",
        "        print(f\"[INFO] Total active parameters after rewiring: {self.count_total_nonzero_weights()}\\n\")\n",
        "\n",
        "def main():\n",
        "    print(\"\\n=== Sparse MLP with Ridge Output Layer for CIFAR-10 ===\")\n",
        "    model = MLP_CIFAR10()\n",
        "\n",
        "    os.makedirs(\"results\", exist_ok=True)\n",
        "    np.savetxt(\"results/dense_mlp_balanced_pruned_rewired_acc.txt\",\n",
        "               np.asarray(model.accuracies_per_epoch))\n",
        "\n",
        "    print(\"\\n=== Training Complete ===\")\n",
        "    print(f\"Final model has {model.count_total_nonzero_weights()} active parameters\")\n",
        "    print(\"Results saved to 'results/dense_mlp_balanced_pruned_rewired_acc.txt'\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-07-04T14:07:18.348739Z",
          "iopub.execute_input": "2025-07-04T14:07:18.349241Z",
          "iopub.status.idle": "2025-07-04T14:07:19.366371Z",
          "shell.execute_reply.started": "2025-07-04T14:07:18.349219Z",
          "shell.execute_reply": "2025-07-04T14:07:19.365789Z"
        },
        "id": "1iKEBjDz__mV",
        "outputId": "d3b771f8-2e8a-4e78-d83f-45170ca89d3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ No GPU found. Running on CPU.\n",
            "\n",
            "=== Sparse MLP with Ridge Output Layer for CIFAR-10 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RpIDD3sDHlQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}